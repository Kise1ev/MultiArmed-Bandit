<h1>📝 Description</h1>
<h3>This project implements a reinforcement learning algorithm to solve the multi-armed bandit problem. The multi-armed bandit is a classical problem in machine learning and operations research that models the situation of choosing between multiple actions (hands) with unknown and varying rewards.</h3>

<h1>📈 Features</h1>
<h3>Bandit Model: The BanditModel class represents an agent that is trained to choose the most profitable action among several options.</h3>
<h3>Optimization method: Stochastic gradient descent method is used to update the model weights.</h3>
<h3>Learning parameters: The learning rate (learning_rate), the exploration parameter (epsilon), the maximum number of iterations (max_iterations) and the maximum number of iterations without changing the correct choice (max_iterations_without_change) can be customized.</h3>

<h1>🔨 Framework</h1>
<p>
    <h3>Visual Studio Code development environment was used to develop the projects</h3>
    <a href="https://code.visualstudio.com/"><img src="https://github.com/Kise1ev/Kise1ev/blob/master/Icons/VSCode-Square.svg"/></a>
    <h3>For this projects was been used Python 3.12.3</h3>
    <a href="https://www.python.org/downloads/release/python-3123/"><img src="https://github.com/Kise1ev/Kise1ev/blob/master/Icons/Python-Square.svg"/></a>
</p>

<h1>📦 Assembling</h1>
<h3>1. Unpack the archive MultiArmed-Bandit-master.zip</h3>
<h3>2. Open terminal in project folder</h3>
<h3>3. Download requirements with command: pip install -r requirements.txt</h3>
<h3>4. To start the project, input command: python main.py</h3>

<h1>💬 Contacts</h1>
<p>
    <a href="https://t.me/kisxlka"><img src="https://github.com/Kise1ev/Kise1ev/blob/master/Icons/Telegram-Square.svg" style="margin-right: 10px;"/></a>
    <a href="https://discordapp.com/users/1013231151177023559"><img src="https://github.com/Kise1ev/Kise1ev/blob/master/Icons/Discord-Square.svg" style="margin-right: 10px;"/></a>
</p>

<h1>©️ Copyright</h1>
<h3>This program was developed by Roman Kiselev. All rights reserved.</h3>
